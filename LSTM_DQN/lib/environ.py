import gym
import gym.spaces
from gym.utils import seeding
import enum
import numpy as np
import time
from utils.AppSetting import AppSetting


class Actions(enum.Enum):
    No_hold = 0
    Buy = 1
    SellShort = 2


class State:
    def __init__(self, bars_count, reset_on_close):
        assert isinstance(bars_count, int)
        assert bars_count > 0
        assert isinstance(reset_on_close, bool)
        self.bars_count = bars_count        
        self.reset_on_close = reset_on_close
        self.alpha = 0
        self.setting = AppSetting.get_LSTM_DQN_setting()
        self.step_index = 0 # ç”¨ä¾†æ¸¬è©¦å‘¼å«äº†stepå¤šå°‘æ¬¡
        
    def reset(self, prices, offset):
        assert offset >= self.bars_count-1        
        self._prices = prices
        self._offset = offset        

        self.count_env_step = 0
        self.current_action = None
        self.update_scale()
        
    @property
    def shape(self):
        return (self.bars_count,self.get_dataFeature_shape(model='RNN'))
    
    def get_dataFeature_shape(self,model:str) ->int:        
        if model == 'RNN':
            # [high,low,close,volume,position]
            return 5
    
    def encode(self):
        """
            [batch_size,seqlength,input_size] (RNNçš„è¼¸å…¥æ¨¡å‹ç‚ºæ­¤)
            
            åœ¨é€™å€‹function è£¡é¢æˆ‘èªç‚º,
                åªéœ€è¦æº–å‚™ [seqlength,input_size]
        """        
        res = np.ndarray(shape= [self.bars_count,self.get_dataFeature_shape(model='RNN')], dtype=np.float32)
        shift = 0
        for bar_idx in range(-self.bars_count, 0):            
            res[shift,0] = self._prices.high[self._offset + bar_idx]            
            res[shift,1] = self._prices.low[self._offset + bar_idx]            
            res[shift,2] = self._prices.close[self._offset + bar_idx]            
            res[shift,3] = self._prices.volume[self._offset + bar_idx]
            res[shift,4] = 0.0 if self.current_action is None else self.current_action
            shift += 1
        
        # ç¢ºå®šè«–æ–‡è£¡é¢æ˜¯æœ‰å°‡éƒ¨ä½ç‹€æ…‹æ”¾å…¥çš„        
        return res

    def _cur_close(self):
        """
        Calculate real close price for the current bar

        # ç‚ºç”šéº¼æœƒé€™æ¨£å¯«çš„åŸå› æ˜¯å› ç‚º é€érel_close ç´€éŒ„çš„å’Œopen price çš„å·®è·(ç™¾åˆ†æ¯”)ä¾†å–å¾—çœŸå¯¦çš„æ”¶ç›¤åƒ¹
        """
        open = self._prices.open[self._offset]
        rel_close = self._prices.close[self._offset]
        return open * (1.0 + rel_close)
    
    def update_scale(self):
        """
            ç‚ºäº†è¦å°‡æ”¶ç›¤åƒ¹æ ¼æ­£å‰‡åŒ–
            æ‰€ä»¥è¦çŸ¥é“æœ€é«˜æœ€ä½åƒ¹
        """
        
        close_array = self._prices.open* (1+self._prices.close)
        self.maxprice = max(close_array)
        self.minprice = min(close_array)
    
    def normalize_price(self, price):
        """
        å¯¹ç»™å®šçš„ä»·æ ¼è¿›è¡Œè§„èŒƒåŒ–ã€‚
        
        å‚æ•°:
        price (float): è¦è§„èŒƒåŒ–çš„ä»·æ ¼ã€‚

        è¿”å›:
        float: è§„èŒƒåŒ–åçš„ä»·æ ¼ã€‚
        """
        return (price - self.minprice) / (self.maxprice - self.minprice)
    
    def calculate_reward(self,sa_current, sa_next, price, alpha):
        """
            1.å®šä¹‰å¥–åŠ±å‡½æ•°:
                å½“ä»£ç†å†³å®šä¹°å…¥æ—¶ï¼Œä»£ç†èŠ±è´¹çš„é’±å°†å¢åŠ ï¼Œå› æ­¤å¥–åŠ±ä¸ºè´Ÿå€¼ã€‚
                å½“ä»£ç†å†³å®šå–å‡ºæ—¶ï¼Œä»£ç†è·å¾—çš„é’±å°†å¢åŠ ï¼Œå› æ­¤å¥–åŠ±ä¸ºæ­£å€¼ã€‚                
                
            2.äº¤æ˜“æˆæœ¬:
                äº¤æ˜“æˆæœ¬é€šè¿‡äº¤æ˜“é‡‘é¢å’Œæˆæœ¬æ¯”ç‡çš„ä¹˜ç§¯è®¡ç®—ã€‚
                
        
        è®¡ç®—å¥–åŠ±å‡½æ•°ã€‚

        å‚æ•°:
        sa_current: å½“å‰æ—¶é—´æ­¥çš„ä»£ç†ä½ç½®çŠ¶æ€ã€‚
        sa_next: ä¸‹ä¸€æ—¶é—´æ­¥çš„ä»£ç†ä½ç½®çŠ¶æ€ã€‚
        p_buy: å½“å‰æ—¶é—´æ­¥çš„ä¹°å…¥ä»·æ ¼ã€‚
        p_sell: å½“å‰æ—¶é—´æ­¥çš„å–å‡ºä»·æ ¼ã€‚
        alpha_buy: è²·å…¥æ™‚çš„äº¤æ˜“æˆæœ¬æ¯”ç‡ã€‚ (æ‰‹çºŒè²»,äº¤æ˜“ç¨…,æ»‘åƒ¹)
        alpha_sell: å–å‡ºæ—¶çš„äº¤æ˜“æˆæœ¬æ¯”ç‡ã€‚

        è¿”å›:
        å¥–åŠ±å€¼ã€‚
        """
        if sa_next > sa_current:
            reward = -abs(sa_next - sa_current) * (1 + alpha) * price
        else:
            reward = abs(sa_next - sa_current) * (1 - alpha) * price

        return reward
    
    def step(self, action):
        """
            é‡æ–°å»ºæ§‹çå‹µ:
                æ¡ç”¨æ–°çš„å…¬å¼å˜—è©¦çœ‹çœ‹
                                
            sa_current: å½“å‰æ—¶é—´æ­¥çš„ä»£ç†ä½ç½®çŠ¶æ€ã€‚
            sa_next: ä¸‹ä¸€æ—¶é—´æ­¥çš„ä»£ç†ä½ç½®çŠ¶æ€ã€‚
            p_buy: å½“å‰æ—¶é—´æ­¥çš„ä¹°å…¥ä»·æ ¼ã€‚
            p_sell: å½“å‰æ—¶é—´æ­¥çš„å–å‡ºä»·æ ¼ã€‚
            alpha_buy: è²·å…¥æ™‚çš„äº¤æ˜“æˆæœ¬æ¯”ç‡ã€‚ (æ‰‹çºŒè²»,äº¤æ˜“ç¨…,æ»‘åƒ¹)
            alpha_sell: å–å‡ºæ—¶çš„äº¤æ˜“æˆæœ¬æ¯”ç‡ã€‚
        """
        assert isinstance(action, Actions)
        
        reward = 0.0
        done = False
        close = self._cur_close()        
        
        
        sa_current = 0.0 if self.current_action is None else self.current_action
        
        if action == Actions.No_hold:       
            sa_next = 0.0 #  if ğ‘ğ‘– = 1,then ğ‘ ğ‘ğ‘–+1 = 1 at the next time step.
        elif action == Actions.Buy:
            sa_next = 1.0
        elif action == Actions.SellShort:
            sa_next = -1.0
        
        self.count_env_step +=1                        
        self._offset += 1
        
        if self.reset_on_close and self.count_env_step >2000:
            done = True
                
        prev_close = close # ä¸Šä¸€æ ¹çš„æ”¶ç›¤åƒ¹
        close = self._cur_close()
        done |= self._offset >= self._prices.close.shape[0]-1        
        self.current_action = sa_next
        
        reward = self.calculate_reward(sa_current=sa_current,
                              sa_next=sa_next,
                              price = self.normalize_price(close),
                              alpha=self.alpha,
        )
        
        
        self.update_alpha()
        return reward, done
    
    
    def update_alpha(self):
        # æ¯æ¬¡è°ƒç”¨æ—¶é€æ­¥å¢åŠ alphaå€¼ï¼Œä½†ä¸è¶…è¿‡æœ€å¤§å€¼
        self.step_index +=1        
        self.alpha = min(self.step_index / 1000000, self.setting['MODEL_DEFAULT_COMMISSION_PERC'] +self.setting['DEFAULT_SLIPPAGE'] )
    



class StocksEnv(gym.Env):
    metadata = {'render.modes': ['human']}

    def __init__(self, prices, bars_count,reset_on_close=True,
                 random_ofs_on_reset=True):

        
        assert isinstance(prices, dict)
        # ç”¨ä¾†è¨˜æ†¶å…¨éƒ¨çš„åƒ¹æ ¼åºåˆ—
        self._prices = prices
        self._state = State(bars_count, reset_on_close)
        self.action_space = gym.spaces.Discrete(n=len(Actions))
        self.observation_space = gym.spaces.Box(
            low=-np.inf, high=np.inf, shape=self._state.shape, dtype=np.float32)
        self.random_ofs_on_reset = random_ofs_on_reset
        self.seed()

    def reset(self):
        self._instrument = self.np_random.choice(list(self._prices.keys()))
        prices = self._prices[self._instrument]

        bars = self._state.bars_count
        if self.random_ofs_on_reset:
            offset = self.np_random.choice(prices.high.shape[0]-bars*10) + bars
        else:
            offset = bars

        self._state.reset(prices, offset)
        return self._state.encode()
    
    def step(self, action_idx):
        """
            å‘¼å«å­é¡_state ä¾†ç²å¾—çå‹µ
        Args:
            action_idx (_type_): _description_

        Returns:
            _type_: _description_
        """
        action = Actions(action_idx)
        reward, done = self._state.step(action) # é€™é‚Šæœƒæ›´æ–°æ­¥æ•¸
        obs = self._state.encode() # å‘¼å«é€™è£¡çš„æ™‚å€™å°±æœƒå–å¾—æ–°çš„ç‹€æ…‹
        info = {"instrument": self._instrument, "offset": self._state._offset}        
        return obs, reward, done, info

    def render(self, mode='human', close=False):
        pass

    def close(self):
        pass

    def seed(self, seed=None):
        self.np_random, seed1 = seeding.np_random(seed)
        seed2 = seeding.hash_seed(seed1 + 1) % 2 ** 31
        return [seed1, seed2]
