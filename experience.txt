2023/12/17:
    設計給DQN,N_STEPS ,確實會讓智能體學會如何玩,而不是每一次都用reset_close,去重置每一場遊戲,
    這樣智能體無法學習到空手的狀態,所以N_steps 我認為非常有效。


    測試內容1 .:
        BTC 最高權益數:
            9W 
            MDD:
            30%
            備註:可以加碼


        樣本外測試:
            商品: [ETH]
            權益數歸零
    
    再次測試:
        新增教育課程,從N_steps 慢慢更新至2000 ,觀察智能體反應。

    結果:
        原始為每10萬步,增加難度
        反應不佳,智能體似乎無法學習到正確的資訊


    再次測試:
        每20萬步,增加難度
        從N_steps 慢慢更新至1000 ,觀察智能體反應。

    結果沒訓練玩成


2023/12/18/:
    直接採用1000步,不逐步添加商品(共12種)